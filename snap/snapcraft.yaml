---
name: ollama
version: v0.6.7
base: core24
summary: Get up and running with large language models locally.
description: |
  Run Llama 2, Code Llama, and other models. Customize and create your own.
adopt-info: ollama
grade: stable
confinement: strict
license: MIT
platforms:
  amd64:
  arm64:

apps:
  ollama:
    command: bin/snap_launcher.sh
    plugs:
      - home
      - removable-media
      - network
      - network-bind
      - opengl # grants also CUDA based GPU access
    environment:
      LD_LIBRARY_PATH: "$SNAP/lib/ollama:/var/lib/snapd/lib/gl${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"
  listener:
    command: bin/snap_launcher.sh serve
    daemon: simple
    install-mode: enable
    restart-condition: on-failure
    refresh-mode: restart
    plugs:
      - home
      - removable-media
      - network
      - network-bind
      - opengl
    environment:
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      LD_LIBRARY_PATH: "$SNAP/lib/ollama:/var/lib/snapd/lib/gl${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"

parts:
  launcher:
    plugin: dump
    source: ./snap/local
    organize:
      snap_launcher.sh: bin/snap_launcher.sh

  ollama:
    plugin: dump
    source: https://github.com/ollama/ollama/releases/download/$SNAPCRAFT_PROJECT_VERSION/ollama-linux-$CRAFT_ARCH_BUILD_FOR.tgz
    prime:
      - -lib/ollama/cuda_v11
